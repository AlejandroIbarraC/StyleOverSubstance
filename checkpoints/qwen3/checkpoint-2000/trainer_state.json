{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.046171782115360195,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.001154294552884005,
      "grad_norm": 0.2395818531513214,
      "learning_rate": 0.00029265,
      "loss": 2.2817,
      "step": 50
    },
    {
      "epoch": 0.00230858910576801,
      "grad_norm": 0.3599849045276642,
      "learning_rate": 0.00028514999999999997,
      "loss": 2.162,
      "step": 100
    },
    {
      "epoch": 0.003462883658652015,
      "grad_norm": 0.3041362166404724,
      "learning_rate": 0.00027764999999999995,
      "loss": 2.1628,
      "step": 150
    },
    {
      "epoch": 0.00461717821153602,
      "grad_norm": 0.26008889079093933,
      "learning_rate": 0.00027015,
      "loss": 2.1623,
      "step": 200
    },
    {
      "epoch": 0.005771472764420024,
      "grad_norm": 0.25702735781669617,
      "learning_rate": 0.00026264999999999996,
      "loss": 2.1404,
      "step": 250
    },
    {
      "epoch": 0.00692576731730403,
      "grad_norm": 0.3288109600543976,
      "learning_rate": 0.00025515,
      "loss": 2.1656,
      "step": 300
    },
    {
      "epoch": 0.008080061870188034,
      "grad_norm": 0.3785979151725769,
      "learning_rate": 0.00024765,
      "loss": 2.0845,
      "step": 350
    },
    {
      "epoch": 0.00923435642307204,
      "grad_norm": 0.35170409083366394,
      "learning_rate": 0.00024014999999999998,
      "loss": 2.1513,
      "step": 400
    },
    {
      "epoch": 0.010388650975956044,
      "grad_norm": 0.35647130012512207,
      "learning_rate": 0.00023264999999999996,
      "loss": 2.1381,
      "step": 450
    },
    {
      "epoch": 0.011542945528840049,
      "grad_norm": 0.36961397528648376,
      "learning_rate": 0.00022514999999999997,
      "loss": 2.1175,
      "step": 500
    },
    {
      "epoch": 0.012697240081724055,
      "grad_norm": 0.32659319043159485,
      "learning_rate": 0.00021764999999999998,
      "loss": 2.1037,
      "step": 550
    },
    {
      "epoch": 0.01385153463460806,
      "grad_norm": 0.34871721267700195,
      "learning_rate": 0.00021014999999999999,
      "loss": 2.1077,
      "step": 600
    },
    {
      "epoch": 0.015005829187492064,
      "grad_norm": 0.354538232088089,
      "learning_rate": 0.00020264999999999997,
      "loss": 2.0943,
      "step": 650
    },
    {
      "epoch": 0.016160123740376068,
      "grad_norm": 0.29594042897224426,
      "learning_rate": 0.00019514999999999997,
      "loss": 2.1382,
      "step": 700
    },
    {
      "epoch": 0.017314418293260074,
      "grad_norm": 0.32596123218536377,
      "learning_rate": 0.00018764999999999998,
      "loss": 2.0752,
      "step": 750
    },
    {
      "epoch": 0.01846871284614408,
      "grad_norm": 0.31464189291000366,
      "learning_rate": 0.00018015,
      "loss": 2.0975,
      "step": 800
    },
    {
      "epoch": 0.019623007399028083,
      "grad_norm": 0.3393140435218811,
      "learning_rate": 0.00017265,
      "loss": 2.0734,
      "step": 850
    },
    {
      "epoch": 0.02077730195191209,
      "grad_norm": 0.3913125693798065,
      "learning_rate": 0.00016514999999999998,
      "loss": 2.0569,
      "step": 900
    },
    {
      "epoch": 0.021931596504796095,
      "grad_norm": 0.5475337505340576,
      "learning_rate": 0.00015764999999999998,
      "loss": 2.0705,
      "step": 950
    },
    {
      "epoch": 0.023085891057680098,
      "grad_norm": 0.3954474627971649,
      "learning_rate": 0.00015014999999999996,
      "loss": 2.0473,
      "step": 1000
    },
    {
      "epoch": 0.024240185610564104,
      "grad_norm": 0.3111599385738373,
      "learning_rate": 0.00014264999999999997,
      "loss": 2.0516,
      "step": 1050
    },
    {
      "epoch": 0.02539448016344811,
      "grad_norm": 0.3788220286369324,
      "learning_rate": 0.00013514999999999998,
      "loss": 2.0482,
      "step": 1100
    },
    {
      "epoch": 0.026548774716332112,
      "grad_norm": 0.37474730610847473,
      "learning_rate": 0.00012764999999999999,
      "loss": 2.0837,
      "step": 1150
    },
    {
      "epoch": 0.02770306926921612,
      "grad_norm": 0.44801053404808044,
      "learning_rate": 0.00012014999999999999,
      "loss": 2.0692,
      "step": 1200
    },
    {
      "epoch": 0.028857363822100125,
      "grad_norm": 0.6287722587585449,
      "learning_rate": 0.00011264999999999999,
      "loss": 2.0397,
      "step": 1250
    },
    {
      "epoch": 0.030011658374984127,
      "grad_norm": 0.33851614594459534,
      "learning_rate": 0.00010514999999999998,
      "loss": 2.0703,
      "step": 1300
    },
    {
      "epoch": 0.031165952927868133,
      "grad_norm": 0.48754820227622986,
      "learning_rate": 9.764999999999999e-05,
      "loss": 2.0521,
      "step": 1350
    },
    {
      "epoch": 0.032320247480752136,
      "grad_norm": 0.9192634224891663,
      "learning_rate": 9.014999999999998e-05,
      "loss": 2.0724,
      "step": 1400
    },
    {
      "epoch": 0.033474542033636145,
      "grad_norm": 0.394715815782547,
      "learning_rate": 8.265e-05,
      "loss": 2.0383,
      "step": 1450
    },
    {
      "epoch": 0.03462883658652015,
      "grad_norm": 0.40202561020851135,
      "learning_rate": 7.515e-05,
      "loss": 2.046,
      "step": 1500
    },
    {
      "epoch": 0.03578313113940415,
      "grad_norm": 0.3763909637928009,
      "learning_rate": 6.764999999999999e-05,
      "loss": 2.0382,
      "step": 1550
    },
    {
      "epoch": 0.03693742569228816,
      "grad_norm": 0.5580949783325195,
      "learning_rate": 6.015e-05,
      "loss": 2.027,
      "step": 1600
    },
    {
      "epoch": 0.03809172024517216,
      "grad_norm": 0.4265366792678833,
      "learning_rate": 5.264999999999999e-05,
      "loss": 2.0335,
      "step": 1650
    },
    {
      "epoch": 0.039246014798056165,
      "grad_norm": 0.40547075867652893,
      "learning_rate": 4.514999999999999e-05,
      "loss": 2.0259,
      "step": 1700
    },
    {
      "epoch": 0.040400309350940175,
      "grad_norm": 0.34144073724746704,
      "learning_rate": 3.7649999999999994e-05,
      "loss": 2.0381,
      "step": 1750
    },
    {
      "epoch": 0.04155460390382418,
      "grad_norm": 0.5143610835075378,
      "learning_rate": 3.0149999999999998e-05,
      "loss": 2.0417,
      "step": 1800
    },
    {
      "epoch": 0.04270889845670818,
      "grad_norm": 0.47871819138526917,
      "learning_rate": 2.2649999999999998e-05,
      "loss": 2.0353,
      "step": 1850
    },
    {
      "epoch": 0.04386319300959219,
      "grad_norm": 0.44528570771217346,
      "learning_rate": 1.5149999999999999e-05,
      "loss": 2.1095,
      "step": 1900
    },
    {
      "epoch": 0.04501748756247619,
      "grad_norm": 0.4078400731086731,
      "learning_rate": 7.65e-06,
      "loss": 2.0389,
      "step": 1950
    },
    {
      "epoch": 0.046171782115360195,
      "grad_norm": 0.49818506836891174,
      "learning_rate": 1.5e-07,
      "loss": 2.0189,
      "step": 2000
    }
  ],
  "logging_steps": 50,
  "max_steps": 2000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7.4438141804544e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
