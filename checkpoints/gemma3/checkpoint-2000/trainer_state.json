{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.09234356423072039,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00230858910576801,
      "grad_norm": 19.130102157592773,
      "learning_rate": 0.00029265,
      "loss": 21.8778,
      "step": 50
    },
    {
      "epoch": 0.00461717821153602,
      "grad_norm": 136.63006591796875,
      "learning_rate": 0.00028514999999999997,
      "loss": 11.6607,
      "step": 100
    },
    {
      "epoch": 0.00692576731730403,
      "grad_norm": 43.60309982299805,
      "learning_rate": 0.00027764999999999995,
      "loss": 9.0636,
      "step": 150
    },
    {
      "epoch": 0.00923435642307204,
      "grad_norm": 60.60786437988281,
      "learning_rate": 0.00027015,
      "loss": 8.2348,
      "step": 200
    },
    {
      "epoch": 0.011542945528840049,
      "grad_norm": 54.44841003417969,
      "learning_rate": 0.00026264999999999996,
      "loss": 9.4247,
      "step": 250
    },
    {
      "epoch": 0.01385153463460806,
      "grad_norm": 25.328916549682617,
      "learning_rate": 0.00025515,
      "loss": 8.3734,
      "step": 300
    },
    {
      "epoch": 0.016160123740376068,
      "grad_norm": 26.6484317779541,
      "learning_rate": 0.00024765,
      "loss": 8.8401,
      "step": 350
    },
    {
      "epoch": 0.01846871284614408,
      "grad_norm": 50.798545837402344,
      "learning_rate": 0.00024014999999999998,
      "loss": 8.0366,
      "step": 400
    },
    {
      "epoch": 0.02077730195191209,
      "grad_norm": 64.08443450927734,
      "learning_rate": 0.00023264999999999996,
      "loss": 8.0208,
      "step": 450
    },
    {
      "epoch": 0.023085891057680098,
      "grad_norm": 56.32727813720703,
      "learning_rate": 0.00022514999999999997,
      "loss": 7.5808,
      "step": 500
    },
    {
      "epoch": 0.02539448016344811,
      "grad_norm": 43.0726432800293,
      "learning_rate": 0.00021764999999999998,
      "loss": 6.3887,
      "step": 550
    },
    {
      "epoch": 0.02770306926921612,
      "grad_norm": 34.710384368896484,
      "learning_rate": 0.00021014999999999999,
      "loss": 7.645,
      "step": 600
    },
    {
      "epoch": 0.030011658374984127,
      "grad_norm": 28.188535690307617,
      "learning_rate": 0.00020264999999999997,
      "loss": 7.3407,
      "step": 650
    },
    {
      "epoch": 0.032320247480752136,
      "grad_norm": 82.2622299194336,
      "learning_rate": 0.00019514999999999997,
      "loss": 6.4703,
      "step": 700
    },
    {
      "epoch": 0.03462883658652015,
      "grad_norm": 17.982187271118164,
      "learning_rate": 0.00018764999999999998,
      "loss": 7.1822,
      "step": 750
    },
    {
      "epoch": 0.03693742569228816,
      "grad_norm": 29.444520950317383,
      "learning_rate": 0.00018015,
      "loss": 6.0983,
      "step": 800
    },
    {
      "epoch": 0.039246014798056165,
      "grad_norm": 42.755313873291016,
      "learning_rate": 0.00017265,
      "loss": 5.8938,
      "step": 850
    },
    {
      "epoch": 0.04155460390382418,
      "grad_norm": 23.611469268798828,
      "learning_rate": 0.00016514999999999998,
      "loss": 7.2942,
      "step": 900
    },
    {
      "epoch": 0.04386319300959219,
      "grad_norm": 95.95854187011719,
      "learning_rate": 0.00015764999999999998,
      "loss": 6.7966,
      "step": 950
    },
    {
      "epoch": 0.046171782115360195,
      "grad_norm": 37.52125549316406,
      "learning_rate": 0.00015014999999999996,
      "loss": 6.825,
      "step": 1000
    },
    {
      "epoch": 0.04848037122112821,
      "grad_norm": 39.36752700805664,
      "learning_rate": 0.00014264999999999997,
      "loss": 5.3864,
      "step": 1050
    },
    {
      "epoch": 0.05078896032689622,
      "grad_norm": 28.64009666442871,
      "learning_rate": 0.00013514999999999998,
      "loss": 6.1771,
      "step": 1100
    },
    {
      "epoch": 0.053097549432664225,
      "grad_norm": 31.05868148803711,
      "learning_rate": 0.00012764999999999999,
      "loss": 5.9381,
      "step": 1150
    },
    {
      "epoch": 0.05540613853843224,
      "grad_norm": 22.02573013305664,
      "learning_rate": 0.00012014999999999999,
      "loss": 5.5021,
      "step": 1200
    },
    {
      "epoch": 0.05771472764420025,
      "grad_norm": 38.80774688720703,
      "learning_rate": 0.00011264999999999999,
      "loss": 6.8415,
      "step": 1250
    },
    {
      "epoch": 0.060023316749968254,
      "grad_norm": 58.87687683105469,
      "learning_rate": 0.00010514999999999998,
      "loss": 6.2575,
      "step": 1300
    },
    {
      "epoch": 0.062331905855736267,
      "grad_norm": 34.793697357177734,
      "learning_rate": 9.764999999999999e-05,
      "loss": 5.8765,
      "step": 1350
    },
    {
      "epoch": 0.06464049496150427,
      "grad_norm": 42.17461395263672,
      "learning_rate": 9.014999999999998e-05,
      "loss": 5.9591,
      "step": 1400
    },
    {
      "epoch": 0.06694908406727229,
      "grad_norm": 65.19172668457031,
      "learning_rate": 8.265e-05,
      "loss": 5.3372,
      "step": 1450
    },
    {
      "epoch": 0.0692576731730403,
      "grad_norm": 72.992919921875,
      "learning_rate": 7.515e-05,
      "loss": 5.9761,
      "step": 1500
    },
    {
      "epoch": 0.0715662622788083,
      "grad_norm": 20.82607078552246,
      "learning_rate": 6.764999999999999e-05,
      "loss": 5.2031,
      "step": 1550
    },
    {
      "epoch": 0.07387485138457632,
      "grad_norm": 27.215124130249023,
      "learning_rate": 6.015e-05,
      "loss": 6.0142,
      "step": 1600
    },
    {
      "epoch": 0.07618344049034433,
      "grad_norm": 16.524982452392578,
      "learning_rate": 5.264999999999999e-05,
      "loss": 5.5645,
      "step": 1650
    },
    {
      "epoch": 0.07849202959611233,
      "grad_norm": 42.76168441772461,
      "learning_rate": 4.514999999999999e-05,
      "loss": 4.9853,
      "step": 1700
    },
    {
      "epoch": 0.08080061870188035,
      "grad_norm": 29.4992618560791,
      "learning_rate": 3.7649999999999994e-05,
      "loss": 5.0302,
      "step": 1750
    },
    {
      "epoch": 0.08310920780764836,
      "grad_norm": 58.7574577331543,
      "learning_rate": 3.0149999999999998e-05,
      "loss": 5.6247,
      "step": 1800
    },
    {
      "epoch": 0.08541779691341636,
      "grad_norm": 19.981040954589844,
      "learning_rate": 2.2649999999999998e-05,
      "loss": 5.1186,
      "step": 1850
    },
    {
      "epoch": 0.08772638601918438,
      "grad_norm": 28.881549835205078,
      "learning_rate": 1.5149999999999999e-05,
      "loss": 5.1895,
      "step": 1900
    },
    {
      "epoch": 0.09003497512495238,
      "grad_norm": 77.36833953857422,
      "learning_rate": 7.65e-06,
      "loss": 5.6995,
      "step": 1950
    },
    {
      "epoch": 0.09234356423072039,
      "grad_norm": 25.91227912902832,
      "learning_rate": 1.5e-07,
      "loss": 5.4448,
      "step": 2000
    }
  ],
  "logging_steps": 50,
  "max_steps": 2000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6.50856070799871e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
