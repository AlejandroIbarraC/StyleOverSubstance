{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.03462883658652015,
  "eval_steps": 500,
  "global_step": 1500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.001154294552884005,
      "grad_norm": 0.6091087460517883,
      "learning_rate": 0.00029265,
      "loss": 2.0102,
      "step": 50
    },
    {
      "epoch": 0.00230858910576801,
      "grad_norm": 0.708688497543335,
      "learning_rate": 0.00028514999999999997,
      "loss": 1.9603,
      "step": 100
    },
    {
      "epoch": 0.003462883658652015,
      "grad_norm": 0.7430446147918701,
      "learning_rate": 0.00027764999999999995,
      "loss": 1.955,
      "step": 150
    },
    {
      "epoch": 0.00461717821153602,
      "grad_norm": 0.5941680669784546,
      "learning_rate": 0.00027015,
      "loss": 1.9612,
      "step": 200
    },
    {
      "epoch": 0.005771472764420024,
      "grad_norm": 0.5302230715751648,
      "learning_rate": 0.00026264999999999996,
      "loss": 1.9338,
      "step": 250
    },
    {
      "epoch": 0.00692576731730403,
      "grad_norm": 0.7442448139190674,
      "learning_rate": 0.00025515,
      "loss": 1.9406,
      "step": 300
    },
    {
      "epoch": 0.008080061870188034,
      "grad_norm": 1.091178059577942,
      "learning_rate": 0.00024765,
      "loss": 1.8774,
      "step": 350
    },
    {
      "epoch": 0.00923435642307204,
      "grad_norm": 0.835982084274292,
      "learning_rate": 0.00024014999999999998,
      "loss": 1.9238,
      "step": 400
    },
    {
      "epoch": 0.010388650975956044,
      "grad_norm": 0.816118597984314,
      "learning_rate": 0.00023264999999999996,
      "loss": 1.914,
      "step": 450
    },
    {
      "epoch": 0.011542945528840049,
      "grad_norm": 0.9519690275192261,
      "learning_rate": 0.00022514999999999997,
      "loss": 1.9078,
      "step": 500
    },
    {
      "epoch": 0.012697240081724055,
      "grad_norm": 0.6206735372543335,
      "learning_rate": 0.00021764999999999998,
      "loss": 1.8866,
      "step": 550
    },
    {
      "epoch": 0.01385153463460806,
      "grad_norm": 0.6926867365837097,
      "learning_rate": 0.00021014999999999999,
      "loss": 1.8877,
      "step": 600
    },
    {
      "epoch": 0.015005829187492064,
      "grad_norm": 0.7673279643058777,
      "learning_rate": 0.00020264999999999997,
      "loss": 1.8771,
      "step": 650
    },
    {
      "epoch": 0.016160123740376068,
      "grad_norm": 0.6975762844085693,
      "learning_rate": 0.00019514999999999997,
      "loss": 1.9208,
      "step": 700
    },
    {
      "epoch": 0.017314418293260074,
      "grad_norm": 0.8026790022850037,
      "learning_rate": 0.00018764999999999998,
      "loss": 1.8554,
      "step": 750
    },
    {
      "epoch": 0.01846871284614408,
      "grad_norm": 0.6657180786132812,
      "learning_rate": 0.00018015,
      "loss": 1.8791,
      "step": 800
    },
    {
      "epoch": 0.019623007399028083,
      "grad_norm": 0.7736746072769165,
      "learning_rate": 0.00017265,
      "loss": 1.8624,
      "step": 850
    },
    {
      "epoch": 0.02077730195191209,
      "grad_norm": 0.7379655241966248,
      "learning_rate": 0.00016514999999999998,
      "loss": 1.8377,
      "step": 900
    },
    {
      "epoch": 0.021931596504796095,
      "grad_norm": 1.152726173400879,
      "learning_rate": 0.00015764999999999998,
      "loss": 1.8452,
      "step": 950
    },
    {
      "epoch": 0.023085891057680098,
      "grad_norm": 0.7636938095092773,
      "learning_rate": 0.00015014999999999996,
      "loss": 1.8359,
      "step": 1000
    },
    {
      "epoch": 0.024240185610564104,
      "grad_norm": 0.7281267046928406,
      "learning_rate": 0.00014264999999999997,
      "loss": 1.834,
      "step": 1050
    },
    {
      "epoch": 0.02539448016344811,
      "grad_norm": 0.7899091839790344,
      "learning_rate": 0.00013514999999999998,
      "loss": 1.8333,
      "step": 1100
    },
    {
      "epoch": 0.026548774716332112,
      "grad_norm": 0.7077670097351074,
      "learning_rate": 0.00012764999999999999,
      "loss": 1.8576,
      "step": 1150
    },
    {
      "epoch": 0.02770306926921612,
      "grad_norm": 0.9521297216415405,
      "learning_rate": 0.00012014999999999999,
      "loss": 1.8412,
      "step": 1200
    },
    {
      "epoch": 0.028857363822100125,
      "grad_norm": 1.0652337074279785,
      "learning_rate": 0.00011264999999999999,
      "loss": 1.8249,
      "step": 1250
    },
    {
      "epoch": 0.030011658374984127,
      "grad_norm": 0.6474377512931824,
      "learning_rate": 0.00010514999999999998,
      "loss": 1.8558,
      "step": 1300
    },
    {
      "epoch": 0.031165952927868133,
      "grad_norm": 0.8624381422996521,
      "learning_rate": 9.764999999999999e-05,
      "loss": 1.8258,
      "step": 1350
    },
    {
      "epoch": 0.032320247480752136,
      "grad_norm": 0.6251180171966553,
      "learning_rate": 9.014999999999998e-05,
      "loss": 1.8455,
      "step": 1400
    },
    {
      "epoch": 0.033474542033636145,
      "grad_norm": 0.7425324320793152,
      "learning_rate": 8.265e-05,
      "loss": 1.831,
      "step": 1450
    },
    {
      "epoch": 0.03462883658652015,
      "grad_norm": 0.8544453382492065,
      "learning_rate": 7.515e-05,
      "loss": 1.8274,
      "step": 1500
    }
  ],
  "logging_steps": 50,
  "max_steps": 2000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.24737931378688e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
