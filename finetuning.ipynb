{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Finetuning Notebook\n",
    "## LLM finetuning for AES\n",
    "\n",
    "Code to finetune models served via Ollama for AES tasks\n",
    "\n",
    "### Create Slim Version of test/train set\n",
    "\n",
    "Remove metadata and just leave scores with texts"
   ],
   "id": "b0a5f455fefb740e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T15:12:55.836915Z",
     "start_time": "2025-07-10T15:12:34.398387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "name_dir = \"data\"\n",
    "file_name_train = \"persuade_corpus_2.0_train.csv\"\n",
    "file_name_test  = \"persuade_corpus_2.0_test.csv\"\n",
    "slim_columns = [\"essay_id_comp\", \"full_text\", \"holistic_essay_score\"]\n",
    "\n",
    "for split, file_name in [(\"train\", file_name_train), (\"test\", file_name_test)]:\n",
    "    fullpath = os.path.join(name_dir, file_name)\n",
    "    print(f\"loading {split} from {fullpath} …\")\n",
    "    df = pd.read_csv(fullpath)\n",
    "\n",
    "    # pick only the three\n",
    "    slim = df[slim_columns].copy()\n",
    "\n",
    "    outpath = os.path.join(name_dir, f\"slim_persuade_{split}.csv\")\n",
    "    print(f\"writing slim {split} -> {outpath}\")\n",
    "    slim.to_csv(outpath, index=False)\n"
   ],
   "id": "48e3662ec2de2a1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train from data\\persuade_corpus_2.0_train.csv …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josea\\AppData\\Local\\Temp\\ipykernel_27472\\3584629915.py:12: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(fullpath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing slim train -> data\\slim_persuade_train.csv\n",
      "loading test from data\\persuade_corpus_2.0_test.csv …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josea\\AppData\\Local\\Temp\\ipykernel_27472\\3584629915.py:12: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(fullpath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing slim test -> data\\slim_persuade_test.csv\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load datasets",
   "id": "dfc378b95cecb6c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T12:53:57.439783Z",
     "start_time": "2025-07-11T12:52:50.917566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "llm_name  = \"mistralai/Mistral-7B-v0.3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_name, use_fast=True)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "raw_ds = load_dataset(\"csv\", data_files={\"train\":\"data/slim_persuade_train.csv\",\n",
    "                                     \"valid\":\"data/slim_persuade_test.csv\"})\n",
    "\n",
    "# prompt for essay scoring\n",
    "def build_prompt(text:str, score:int) -> str:\n",
    "    return (\n",
    "        \"<s>[INST] You are an essay rater specializing in the evaluation of essays written by students from 6th to 12th grade. \"\n",
    "        \"Read and evaluate the essay. Assign it a score from 1 to 6, in increments of 1. \"\n",
    "        \"Your response should be only a numeric value representing the score you gave. [/INST]\\n\"\n",
    "        f\"{text.strip()}\\n\"\n",
    "        f\"</s> {score}\"\n",
    "    )\n",
    "\n",
    "# tokenize and format for pytorch\n",
    "def preprocess(ex):\n",
    "    prompt = build_prompt(ex[\"full_text\"], ex[\"holistic_essay_score\"])\n",
    "    tok    = tokenizer(prompt,\n",
    "                       truncation=True,\n",
    "                       max_length=2048,\n",
    "                       padding=\"max_length\")\n",
    "    tok[\"labels\"] = tok[\"input_ids\"].copy()\n",
    "    return tok\n",
    "\n",
    "ds = raw_ds.map(preprocess, batched=False, remove_columns=raw_ds[\"train\"].column_names)\n",
    "ds.set_format(\"torch\")"
   ],
   "id": "adb10fa824ed7a9e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-11T12:54:17.969713Z",
     "start_time": "2025-07-11T12:53:58.566809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "\n",
    "# 4-bit quantization config\n",
    "bnb_cfg = BitsAndBytesConfig(\n",
    "    load_in_4bit            = True,\n",
    "    bnb_4bit_quant_type     = \"nf4\",\n",
    "    bnb_4bit_compute_dtype  = \"float16\",\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "# load model & tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    llm_name,\n",
    "    quantization_config=bnb_cfg,\n",
    "    device_map=\"auto\",\n",
    "    # trust_remote_code=True  # Gemma needs this\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# prepare PEFT (LoRA) adapter\n",
    "peft_cfg = LoraConfig(\n",
    "    r           = 8,\n",
    "    lora_alpha  = 16,\n",
    "    lora_dropout= 0.05,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"]\n",
    ")\n",
    "model = get_peft_model(model, peft_cfg)\n",
    "model.print_trainable_parameters()"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "11769bdb9a6f43e28828726721f0778a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,407,872 || all params: 7,251,431,424 || trainable%: 0.0470\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-07-11T12:56:20.047304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "\n",
    "import os, torch\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir            = \"checkpoints\",\n",
    "    per_device_train_batch_size = 1,\n",
    "    gradient_accumulation_steps = 4,\n",
    "    eval_accumulation_steps     = 1,\n",
    "    learning_rate         = 3e-4,\n",
    "    fp16                  = True,\n",
    "    num_train_epochs      = 1,\n",
    "    max_steps             = 2000,\n",
    "    logging_steps         = 50,\n",
    "    eval_steps            = 500,\n",
    "    save_steps            = 500,\n",
    "    save_total_limit      = 2,\n",
    "    report_to             = \"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model         = model,\n",
    "    args          = training_args,\n",
    "    train_dataset = ds[\"train\"],\n",
    "    eval_dataset  = ds[\"valid\"],\n",
    "    data_collator = data_collator,\n",
    "    tokenizer     = tokenizer\n",
    ")\n",
    "\n",
    "import time\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "class StepLogger(TrainerCallback):\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        if state.global_step % 100 == 0:\n",
    "            print(f\"[{time.strftime('%H:%M:%S')}] Complete step {state.global_step}\")\n",
    "\n",
    "trainer.add_callback(StepLogger())\n",
    "\n",
    "trainer.train()"
   ],
   "id": "825dfbdb71c59186",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josea\\AppData\\Local\\Temp\\ipykernel_1520\\1437183572.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModel`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "C:\\Users\\josea\\Documents\\Development\\StyleOverSubstance\\.venv1\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1498' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1498/2000 5:34:50 < 1:52:21, 0.07 it/s, Epoch 0.03/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.010200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.960300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.961200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.933800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.940600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.877400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.923800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.914000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.907800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.886600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.887700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.877100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.920800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.855400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.879100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.862400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.837700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.845200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.835900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>1.834000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.833300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>1.857600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.841200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>1.824900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.855800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>1.825800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.845500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>1.831000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:18:39] Complete step 100\n",
      "[14:41:08] Complete step 200\n",
      "[15:03:33] Complete step 300\n",
      "[15:26:05] Complete step 400\n",
      "[15:48:33] Complete step 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josea\\Documents\\Development\\StyleOverSubstance\\.venv1\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:10:59] Complete step 600\n",
      "[16:33:26] Complete step 700\n",
      "[16:55:50] Complete step 800\n",
      "[17:18:16] Complete step 900\n",
      "[17:40:40] Complete step 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josea\\Documents\\Development\\StyleOverSubstance\\.venv1\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:02:57] Complete step 1100\n",
      "[18:25:18] Complete step 1200\n",
      "[18:47:35] Complete step 1300\n",
      "[19:09:50] Complete step 1400\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e05a47605e77d206"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
